Spark Executor Command: "/Library/Java/JavaVirtualMachines/jdk-15.0.1.jdk/Contents/Home/bin/java" "-cp" "/Users/baotran/Desktop/Spark+Docker/spark-3.0.1-bin-hadoop2.7/conf/:/Users/baotran/Desktop/Spark+Docker/spark-3.0.1-bin-hadoop2.7/jars/*" "-Xmx1024M" "-Dspark.driver.port=52715" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@baos-mbp:52715" "--executor-id" "0" "--hostname" "172.27.0.67" "--cores" "1" "--app-id" "app-20201122013236-0000" "--worker-url" "spark://Worker@172.27.0.67:52703"
========================================

Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
20/11/22 01:32:38 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 6908@Baos-MBP
20/11/22 01:32:38 INFO SignalUtils: Registered signal handler for TERM
20/11/22 01:32:38 INFO SignalUtils: Registered signal handler for HUP
20/11/22 01:32:38 INFO SignalUtils: Registered signal handler for INT
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/baotran/Desktop/Spark+Docker/spark-3.0.1-bin-hadoop2.7/jars/spark-unsafe_2.12-3.0.1.jar) to constructor java.nio.DirectByteBuffer(long,int)
WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
20/11/22 01:32:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
20/11/22 01:32:39 INFO SecurityManager: Changing view acls to: baotran
20/11/22 01:32:39 INFO SecurityManager: Changing modify acls to: baotran
20/11/22 01:32:39 INFO SecurityManager: Changing view acls groups to: 
20/11/22 01:32:39 INFO SecurityManager: Changing modify acls groups to: 
20/11/22 01:32:39 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(baotran); groups with view permissions: Set(); users  with modify permissions: Set(baotran); groups with modify permissions: Set()
20/11/22 01:32:39 INFO TransportClientFactory: Successfully created connection to baos-mbp/172.27.0.67:52715 after 129 ms (0 ms spent in bootstraps)
20/11/22 01:32:40 INFO SecurityManager: Changing view acls to: baotran
20/11/22 01:32:40 INFO SecurityManager: Changing modify acls to: baotran
20/11/22 01:32:40 INFO SecurityManager: Changing view acls groups to: 
20/11/22 01:32:40 INFO SecurityManager: Changing modify acls groups to: 
20/11/22 01:32:40 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(baotran); groups with view permissions: Set(); users  with modify permissions: Set(baotran); groups with modify permissions: Set()
20/11/22 01:32:40 INFO TransportClientFactory: Successfully created connection to baos-mbp/172.27.0.67:52715 after 3 ms (0 ms spent in bootstraps)
20/11/22 01:32:40 INFO DiskBlockManager: Created local directory at /private/var/folders/j3/z5zmcbt16d1csdxhj0381gjr0000gn/T/spark-1ca89d1d-e669-4fa8-ae06-ace5669efd95/executor-7b475a9c-165a-4082-afe0-099367d508b6/blockmgr-082ef134-c99b-469d-9086-89005fa0ba3f
20/11/22 01:32:40 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
20/11/22 01:32:40 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@baos-mbp:52715
20/11/22 01:32:40 INFO WorkerWatcher: Connecting to worker spark://Worker@172.27.0.67:52703
20/11/22 01:32:40 INFO TransportClientFactory: Successfully created connection to /172.27.0.67:52703 after 2 ms (0 ms spent in bootstraps)
20/11/22 01:32:40 INFO ResourceUtils: ==============================================================
20/11/22 01:32:40 INFO WorkerWatcher: Successfully connected to spark://Worker@172.27.0.67:52703
20/11/22 01:32:40 INFO ResourceUtils: Resources for spark.executor:

20/11/22 01:32:40 INFO ResourceUtils: ==============================================================
20/11/22 01:32:40 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
20/11/22 01:32:40 INFO Executor: Starting executor ID 0 on host 172.27.0.67
20/11/22 01:32:40 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52721.
20/11/22 01:32:40 INFO NettyBlockTransferService: Server created on 172.27.0.67:52721
20/11/22 01:32:40 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/11/22 01:32:40 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.27.0.67, 52721, None)
20/11/22 01:32:40 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.27.0.67, 52721, None)
20/11/22 01:32:40 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.27.0.67, 52721, None)
20/11/22 01:32:40 INFO Executor: Using REPL class URI: spark://baos-mbp:52715/classes
20/11/22 01:33:47 INFO CoarseGrainedExecutorBackend: Got assigned task 0
20/11/22 01:33:47 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
20/11/22 01:33:48 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
20/11/22 01:33:49 INFO TransportClientFactory: Successfully created connection to baos-mbp/172.27.0.67:52717 after 2 ms (0 ms spent in bootstraps)
20/11/22 01:33:49 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 1787.0 B, free 434.4 MiB)
20/11/22 01:33:49 INFO TorrentBroadcast: Reading broadcast variable 0 took 1168 ms
20/11/22 01:33:49 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 3.0 KiB, free 434.4 MiB)
20/11/22 01:33:49 INFO TransportClientFactory: Successfully created connection to baos-mbp/172.27.0.67:52715 after 2 ms (0 ms spent in bootstraps)
20/11/22 01:33:49 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 918 bytes result sent to driver
20/11/22 01:33:49 INFO CoarseGrainedExecutorBackend: Got assigned task 1
20/11/22 01:33:49 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
20/11/22 01:33:49 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 875 bytes result sent to driver
20/11/22 02:02:56 WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:913)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:200)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1932)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:294)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 12 more
20/11/22 02:02:59 WARN TransportResponseHandler: Ignoring response for RPC 5132523889193059470 from baos-mbp/172.27.0.67:52715 (81 bytes) since it is not outstanding
20/11/22 12:04:27 WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:913)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:200)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1932)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:294)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 12 more
20/11/22 12:04:33 WARN NettyRpcEnv: Ignored failure: java.util.concurrent.TimeoutException: Cannot receive any reply from baos-mbp:52715 in 10000 milliseconds
20/11/22 12:04:33 INFO Executor: Told to re-register on heartbeat
20/11/22 12:04:34 INFO BlockManager: BlockManager BlockManagerId(0, 172.27.0.67, 52721, None) re-registering with master
20/11/22 12:04:34 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.27.0.67, 52721, None)
20/11/22 12:04:36 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.27.0.67, 52721, None)
20/11/22 12:04:36 INFO BlockManager: Reporting 0 blocks to the master.
20/11/22 12:04:36 INFO Executor: Told to re-register on heartbeat
20/11/22 12:04:36 INFO BlockManager: BlockManager BlockManagerId(0, 172.27.0.67, 52721, None) re-registering with master
20/11/22 12:04:36 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.27.0.67, 52721, None)
20/11/22 12:04:36 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.27.0.67, 52721, None)
20/11/22 12:04:36 INFO BlockManager: Reporting 0 blocks to the master.
20/11/22 12:04:36 INFO Executor: Told to re-register on heartbeat
20/11/22 12:04:36 INFO BlockManager: BlockManager BlockManagerId(0, 172.27.0.67, 52721, None) re-registering with master
20/11/22 12:04:36 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.27.0.67, 52721, None)
20/11/22 12:04:36 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.27.0.67, 52721, None)
20/11/22 12:04:36 INFO BlockManager: Reporting 0 blocks to the master.
20/11/22 12:04:36 INFO Executor: Told to re-register on heartbeat
20/11/22 12:04:36 INFO BlockManager: BlockManager BlockManagerId(0, 172.27.0.67, 52721, None) re-registering with master
20/11/22 12:04:36 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.27.0.67, 52721, None)
20/11/22 12:04:36 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.27.0.67, 52721, None)
20/11/22 12:04:36 INFO BlockManager: Reporting 0 blocks to the master.
20/11/22 12:04:36 INFO Executor: Told to re-register on heartbeat
20/11/22 12:04:36 INFO BlockManager: BlockManager BlockManagerId(0, 172.27.0.67, 52721, None) re-registering with master
20/11/22 12:04:36 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.27.0.67, 52721, None)
20/11/22 12:04:36 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.27.0.67, 52721, None)
20/11/22 12:04:36 INFO BlockManager: Reporting 0 blocks to the master.
20/11/22 12:04:37 INFO Executor: Told to re-register on heartbeat
20/11/22 12:04:37 INFO BlockManager: BlockManager BlockManagerId(0, 172.27.0.67, 52721, None) re-registering with master
20/11/22 12:04:37 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.27.0.67, 52721, None)
20/11/22 12:04:37 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.27.0.67, 52721, None)
20/11/22 12:04:37 INFO BlockManager: Reporting 0 blocks to the master.
20/11/22 12:04:43 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
20/11/22 12:04:44 INFO MemoryStore: MemoryStore cleared
20/11/22 12:04:44 INFO BlockManager: BlockManager stopped
20/11/22 12:04:45 INFO ShutdownHookManager: Shutdown hook called
